{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmanuel-olateju/EmotiSpot/blob/main/data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YB63XS6935lG",
        "outputId": "c41af337-a573-44cd-d644-7faf6a773683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/khan1803115/eeg-dataset-for-emotion-recognition\n",
            "License(s): Apache 2.0\n",
            "Downloading eeg-dataset-for-emotion-recognition.zip to /content\n",
            " 94% 171M/181M [00:02<00:00, 87.2MB/s]\n",
            "100% 181M/181M [00:02<00:00, 71.6MB/s]\n",
            "Archive:  eeg-dataset-for-emotion-recognition.zip\n",
            "  inflating: datasets/khan1803115/Data/S01G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S01G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S01G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S01G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S02G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S02G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S02G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S02G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S03G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S03G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S03G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S03G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S04G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S04G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S04G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S04G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S05G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S05G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S05G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S05G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S06G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S06G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S06G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S06G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S07G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S07G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S07G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S07G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S08G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S08G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S08G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S08G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S09G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S09G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S09G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S09G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S10G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S10G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S10G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S10G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S11G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S11G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S11G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S11G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S12G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S12G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S12G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S12G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S13G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S13G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S13G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S13G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S14G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S14G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S14G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S14G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S15G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S15G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S15G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S15G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S16G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S16G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S16G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S16G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S17G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S17G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S17G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S17G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S18G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S18G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S18G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S18G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S19G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S19G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S19G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S19G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S20G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S20G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S20G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S20G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S21G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S21G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S21G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S21G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S22G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S22G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S22G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S22G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S23G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S23G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S23G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S23G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S24G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S24G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S24G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S24G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S25G1AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S25G2AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S25G3AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/Data/S25G4AllChannels.csv  \n",
            "  inflating: datasets/khan1803115/arousal_normalize.csv  \n",
            "  inflating: datasets/khan1803115/valence_normalize.csv  \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d khan1803115/eeg-dataset-for-emotion-recognition\n",
        "!mkdir -p datasets/khan1803115\n",
        "!unzip eeg-dataset-for-emotion-recognition.zip -d datasets/khan1803115/\n",
        "!rm eeg-dataset-for-emotion-recognition.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZTyKZUes35lK",
        "outputId": "7159ebcf-47ec-40ef-bcb4-700778cfd9ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.7.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.3)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.1)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.2.2)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.7.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install mne\n",
        "import mne"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# from google.colab import files\n",
        "\n",
        "def save_artifact(artifact,name):\n",
        "  joblib.dump(artifact,name)\n",
        "  # files.download(name)\n"
      ],
      "metadata": {
        "id": "Kt_3rd-gDRmC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "NVDn5pxR7c8F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rFeHh7wM35lN"
      },
      "outputs": [],
      "source": [
        "khan_dataset_dir = \"datasets/khan1803115/\"\n",
        "valence = pd.read_csv(khan_dataset_dir+\"valence_normalize.csv\")\n",
        "arousal = pd.read_csv(khan_dataset_dir+\"arousal_normalize.csv\")\n",
        "data = [pd.read_csv(khan_dataset_dir+\"Data/\"+file) for file in os.listdir(khan_dataset_dir+\"Data/\")]\n",
        "\n",
        "channels = data[0].columns[:-2]\n",
        "label_columns = data[0].columns[-2:]\n",
        "fs = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bVcaE36a35lP",
        "outputId": "85a55919-bd86-4061-eb97-2bc3c042ec97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 38000, 14), (100, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "eeg_data = np.array([data_[channels][:38000] for data_ in data])\n",
        "valence_arousal_values = np.array([data_[label_columns].mean() for data_ in data])\n",
        "eeg_data.shape, valence_arousal_values.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q0bTIYbe35lU",
        "outputId": "f5110585-f309-4c1c-8787-3370fc3eed2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 34, 1280, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Make use of 1250 samples for an epoch with 500 samples overlapping between succesive epochs\n",
        "epoch_starting_points = np.arange(0,38252,1280-256)[:-4]\n",
        "\n",
        "eeg_epochs = []\n",
        "\n",
        "for i in range(len(data)):\n",
        "    epochs = []\n",
        "    for epoch_starting_point in epoch_starting_points:\n",
        "        epochs.append(eeg_data[i,epoch_starting_point:epoch_starting_point+1280,:])\n",
        "\n",
        "    eeg_epochs.append(epochs)\n",
        "\n",
        "eeg_epochs = np.array(eeg_epochs)\n",
        "\n",
        "eeg_epochs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v-udIKHt35lZ",
        "outputId": "f5713dc9-e25e-40bb-907b-a13d8815e2eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 34, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "epoch_targets = []\n",
        "\n",
        "for i in range(len(data)):\n",
        "  targets = [valence_arousal_values[i]]*34\n",
        "  epoch_targets.append(targets)\n",
        "\n",
        "epoch_targets = np.array(epoch_targets)\n",
        "\n",
        "epoch_targets.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_epochs = eeg_epochs.reshape(3400,1280,14)\n",
        "epoch_targets = epoch_targets.reshape(3400,2)\n",
        "\n",
        "eeg_epochs.shape, epoch_targets.shape"
      ],
      "metadata": {
        "id": "Er9vFgVY5RjF",
        "outputId": "d12d4344-05c9-4913-c732-a86beb5f2081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3400, 1280, 14), (3400, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save_artifact(eeg_epochs,\"EEG_DATA.np\")"
      ],
      "metadata": {
        "id": "VnZaV41EEGxa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "2uNF-ipu7fDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lowcut = 1\n",
        "highcut = 45\n",
        "\n",
        "filtered_eeg_epochs = np.empty((3400,1280,14))\n",
        "\n",
        "for e,epoch in enumerate(eeg_epochs):\n",
        "  filtered = mne.filter.filter_data(epoch.T,fs,lowcut,highcut,verbose=0)\n",
        "  filtered_eeg_epochs[e,:,:] = filtered.T\n",
        "\n",
        "filtered_eeg_epochs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Fq5rX4Fgc3",
        "outputId": "6beb7b71-d0e9-42e1-ac78-254cdd40f5fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3400, 1280, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save_artifact(filtered_eeg_epochs,\"FILTERED_EEG_DATA.np\")\n",
        "# save_artifact(epoch_targets,\"EEG_VALENCE_AROUSAL_TARGETS.np\")"
      ],
      "metadata": {
        "id": "yPvHZDko9Fvu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Dataloader"
      ],
      "metadata": {
        "id": "d0Wf8qxQIg8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, features, targets, transform=None):\n",
        "    self.features = features\n",
        "    self.targets = targets\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    feature = self.features[idx]\n",
        "    target = self.targets[idx]\n",
        "    if self.transform:\n",
        "      feature = self.transform(feature)\n",
        "    return feature, target"
      ],
      "metadata": {
        "id": "1M9BZsPpIgSa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size_ = 10\n",
        "shuffle_ = True\n",
        "num_workers_ = 5\n",
        "dataset = CustomDataset(filtered_eeg_epochs.astype(float),epoch_targets.astype(float))\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size_,shuffle=shuffle_,num_workers=num_workers_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsE4BGFMO9gM",
        "outputId": "ef7ce82d-32ce-4df4-bf64-7f36579060c4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling"
      ],
      "metadata": {
        "id": "441UMr7QGgAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F"
      ],
      "metadata": {
        "id": "pspPsdbpFwSE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mlp(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(mlp,self).__init__()\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.Linear(1280*14,100),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(100,2),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(2,2),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x.view(x.size()[0],-1)\n",
        "    x = self.fc1(x.to(torch.float32))\n",
        "    return x"
      ],
      "metadata": {
        "id": "2NtjORCgH0-A"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlpn = mlp()\n",
        "\n",
        "for batch_idx, (X,y) in enumerate(dataloader):\n",
        "  res = mlpn(X)\n",
        "  print(res.size())"
      ],
      "metadata": {
        "id": "ZLgY1HVJIabc",
        "outputId": "9081b07a-91e8-40d7-d07f-4617c970cf3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n",
            "torch.Size([10, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1280*14"
      ],
      "metadata": {
        "id": "mZ7fN_u0QJzx",
        "outputId": "4ab7d4f2-9f4a-4497-b5a6-a24983dc0ca7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17920"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3PadJPURcQs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}