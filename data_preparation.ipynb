{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/khan1803115/eeg-dataset-for-emotion-recognition\n",
      "License(s): Apache 2.0\n",
      "Downloading eeg-dataset-for-emotion-recognition.zip to /home/petron/Documents/work/EmotiSpot\n",
      "100%|████████████████████████████████████████| 181M/181M [01:05<00:00, 3.36MB/s]\n",
      "100%|████████████████████████████████████████| 181M/181M [01:05<00:00, 2.89MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d khan1803115/eeg-dataset-for-emotion-recognition\n",
    "!mkdir -p datasets/khan1803115\n",
    "!unzip eeg-dataset-for-emotion-recognition.zip -d datasets/khan1803115/\n",
    "!rm eeg-dataset-for-emotion-recognition.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "khan_dataset_dir = \"datasets/khan1803115/\"\n",
    "valence = pd.read_csv(khan_dataset_dir+\"valence_normalize.csv\")\n",
    "arousal = pd.read_csv(khan_dataset_dir+\"arousal_normalize.csv\")\n",
    "data = [pd.read_csv(khan_dataset_dir+\"Data/\"+file) for file in os.listdir(khan_dataset_dir+\"Data/\")]\n",
    "\n",
    "channels = data[0].columns[:-2]\n",
    "label_columns = data[0].columns[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 38000, 14), (100, 2))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_data = np.array([data_[channels][:38000] for data_ in data])\n",
    "valence_arousal_values = np.array([data_[label_columns].mean() for data_ in data])\n",
    "eeg_data.shape, valence_arousal_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make use of 1250 samples for an epoch with 500 samples overlapping between succesive epochs\n",
    "epoch_starting_points = np.arange(0,38252,250)[:-4]\n",
    "\n",
    "eeg_epochs = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    epochs = []\n",
    "    for epoch_starting_point in epoch_starting_points:\n",
    "        epochs.append(eeg_data[i,epoch_starting_point:epoch_starting_point+750,:])\n",
    "\n",
    "    eeg_epochs.append(epochs)\n",
    "\n",
    "eeg_epochs = np.array(eeg_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37250"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36000+1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroBCI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
