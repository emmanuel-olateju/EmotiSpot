{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmanuel-olateju/EmotiSpot/blob/main/data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB63XS6935lG",
        "outputId": "490cd2ee-8fe6-4cef-a4ac-8f0b3a725daa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/khan1803115/eeg-dataset-for-emotion-recognition\n",
            "License(s): Apache 2.0\n",
            "Downloading eeg-dataset-for-emotion-recognition.zip to /content\n",
            " 96% 174M/181M [00:02<00:00, 105MB/s]\n",
            "100% 181M/181M [00:02<00:00, 68.3MB/s]\n",
            "Archive:  eeg-dataset-for-emotion-recognition.zip\n",
            "replace datasets/khan1803115/Data/S01G1AllChannels.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d khan1803115/eeg-dataset-for-emotion-recognition\n",
        "!mkdir -p datasets/khan1803115\n",
        "!unzip eeg-dataset-for-emotion-recognition.zip -d datasets/khan1803115/\n",
        "!rm eeg-dataset-for-emotion-recognition.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZTyKZUes35lK",
        "outputId": "c8dc4e15-ecb3-4195-c002-f0a2be501b64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.7.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.3)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.1)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.2.2)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.7.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install mne\n",
        "import mne"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# from google.colab import files\n",
        "\n",
        "def save_artifact(artifact,name):\n",
        "  joblib.dump(artifact,name)\n",
        "  # files.download(name)\n"
      ],
      "metadata": {
        "id": "Kt_3rd-gDRmC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "NVDn5pxR7c8F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rFeHh7wM35lN"
      },
      "outputs": [],
      "source": [
        "khan_dataset_dir = \"datasets/khan1803115/\"\n",
        "valence = pd.read_csv(khan_dataset_dir+\"valence_normalize.csv\")\n",
        "arousal = pd.read_csv(khan_dataset_dir+\"arousal_normalize.csv\")\n",
        "data = [pd.read_csv(khan_dataset_dir+\"Data/\"+file) for file in os.listdir(khan_dataset_dir+\"Data/\")]\n",
        "\n",
        "channels = data[0].columns[:-2]\n",
        "label_columns = data[0].columns[-2:]\n",
        "fs = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bVcaE36a35lP",
        "outputId": "ed477ed3-9cb5-4e4d-a6a0-e981bae44aba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 38000, 14), (100, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "eeg_data = np.array([data_[channels][:38000] for data_ in data])\n",
        "valence_arousal_values = np.array([data_[label_columns].mean() for data_ in data])\n",
        "eeg_data.shape, valence_arousal_values.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q0bTIYbe35lU",
        "outputId": "f4439a47-3677-483d-d224-f6ce2e1055d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 34, 1280, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Make use of 1250 samples for an epoch with 500 samples overlapping between succesive epochs\n",
        "epoch_starting_points = np.arange(0,38252,1280-256)[:-4]\n",
        "\n",
        "eeg_epochs = []\n",
        "\n",
        "for i in range(len(data)):\n",
        "    epochs = []\n",
        "    for epoch_starting_point in epoch_starting_points:\n",
        "        epochs.append(eeg_data[i,epoch_starting_point:epoch_starting_point+1280,:])\n",
        "\n",
        "    eeg_epochs.append(epochs)\n",
        "\n",
        "eeg_epochs = np.array(eeg_epochs)\n",
        "\n",
        "eeg_epochs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v-udIKHt35lZ",
        "outputId": "100ddcf3-3e9d-4b43-d134-94953b461e4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 34, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "epoch_targets = []\n",
        "\n",
        "for i in range(len(data)):\n",
        "  targets = [valence_arousal_values[i]]*34\n",
        "  epoch_targets.append(targets)\n",
        "\n",
        "epoch_targets = np.array(epoch_targets)\n",
        "\n",
        "epoch_targets.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_epochs = eeg_epochs.reshape(3400,1280,14)\n",
        "epoch_targets = epoch_targets.reshape(3400,2)\n",
        "\n",
        "eeg_epochs.shape, epoch_targets.shape"
      ],
      "metadata": {
        "id": "Er9vFgVY5RjF",
        "outputId": "2ce89680-c149-4fc4-a52d-72de76485f93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3400, 1280, 14), (3400, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save_artifact(eeg_epochs,\"EEG_DATA.np\")"
      ],
      "metadata": {
        "id": "VnZaV41EEGxa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "2uNF-ipu7fDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lowcut = 1\n",
        "highcut = 45\n",
        "\n",
        "filtered_eeg_epochs = np.empty((3400,1280,14))\n",
        "\n",
        "for e,epoch in enumerate(eeg_epochs):\n",
        "  filtered = mne.filter.filter_data(epoch.T,fs,lowcut,highcut,verbose=0)\n",
        "  filtered_eeg_epochs[e,:,:] = filtered.T\n",
        "\n",
        "filtered_eeg_epochs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Fq5rX4Fgc3",
        "outputId": "8e92a6ca-69a0-4efb-d2ba-7cbf68be7789"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3400, 1280, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save_artifact(filtered_eeg_epochs,\"FILTERED_EEG_DATA.np\")\n",
        "# save_artifact(epoch_targets,\"EEG_VALENCE_AROUSAL_TARGETS.np\")"
      ],
      "metadata": {
        "id": "yPvHZDko9Fvu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Dataloader"
      ],
      "metadata": {
        "id": "d0Wf8qxQIg8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = filtered_eeg_epochs, epoch_targets\n",
        "\n",
        "X_train, X_, y_train, y_ = train_test_split(X, y, test_size=0.40, random_state=100)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_, y_, test_size=0.5, random_state=100)\n",
        "\n",
        "print(f\" Train Size :({X_train.shape}, {y_train.shape}) | Test Size : ({X_test.shape}, {y_test.shape}) | Validation Size: ({X_val.shape}, {y_val.shape})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXHx_swdpc0u",
        "outputId": "e9a8de26-dbf5-4220-b885-c817b897d87d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train Size :((2040, 1280, 14), (2040, 2)) | Test Size : ((680, 1280, 14), (680, 2)) | Validation Size: ((680, 1280, 14), (680, 2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, features, targets, transform=None):\n",
        "    self.features = features\n",
        "    self.targets = targets\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    feature = self.features[idx]\n",
        "    target = self.targets[idx]\n",
        "    if self.transform:\n",
        "      feature = self.transform(feature)\n",
        "    return feature, target"
      ],
      "metadata": {
        "id": "1M9BZsPpIgSa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch_size = 10\n",
        "shuffle_ = True\n",
        "num_workers_ = 5\n",
        "\n",
        "# Make Train Dataloader\n",
        "train_dataset = CustomDataset(X_train.astype(float),y_train.astype(float))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=shuffle_, num_workers=num_workers_)\n",
        "\n",
        "# Make Validation Dataloader\n",
        "val_batch_size = 5\n",
        "val_dataset = CustomDataset(X_val.astype(float),y_val.astype(float))\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=shuffle_, num_workers=num_workers_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsE4BGFMO9gM",
        "outputId": "d6e02b11-04f7-48a1-905b-8ea5cbd778d2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling"
      ],
      "metadata": {
        "id": "441UMr7QGgAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "pspPsdbpFwSE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mlp(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(mlp,self).__init__()\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.Linear(1280*14,100),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(100,2),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(2,2),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x.view(x.size()[0],-1)\n",
        "    x = self.fc1(x.to(torch.float32))\n",
        "    return x"
      ],
      "metadata": {
        "id": "2NtjORCgH0-A"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlpn = mlp()\n",
        "\n",
        "epochs = 200\n",
        "lr_ = 0.001\n",
        "\n",
        "optimizer = optim.SGD(mlpn.parameters(),lr=lr_)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "train_loss, val_loss = [], []\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "  running_loss = 0.0\n",
        "  val_running_loss = 0.0\n",
        "\n",
        "  for batch, (x_,y_) in enumerate(train_dataloader):\n",
        "\n",
        "    x_ = x_.to(torch.float)\n",
        "    y_ = y_.to(torch.float)\n",
        "\n",
        "    mlpn =mlpn.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_est = mlpn(x_)\n",
        "    y_est = y_est.requires_grad_(True)\n",
        "\n",
        "    loss = loss_fn(y_est,y_)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    x_val,y_val = val_dataloader(random.randint(0,len(val_dataloader)-1)):\n",
        "    x_val = x_val.to(torch.float)\n",
        "    y_val = y_val.to(torch.float)\n",
        "\n",
        "    mlpn = mlpn.eval()\n",
        "\n",
        "    y_est = mlpn(x_val)\n",
        "\n",
        "    loss = loss_fn(y_est,y_val)\n",
        "    val_running_loss += loss.item()\n",
        "\n",
        "  print(\"----------------------------------------------------------------------------------\")\n",
        "  print(f\"Epoch: {e}/{epochs} | loss: {running_loss} |  validation loss: {val_running_loss}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "ZLgY1HVJIabc",
        "outputId": "0fc011d1-79da-4d78-f1e8-bb466702640b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------\n",
            "Epoch: 0/200 | loss: 1801.5997223854065\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 1/200 | loss: 1530.1408817768097\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 2/200 | loss: 1368.1157517433167\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 3/200 | loss: 1266.037337064743\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 4/200 | loss: 1178.085364818573\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 5/200 | loss: 1036.771112203598\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 6/200 | loss: 862.7694847583771\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 7/200 | loss: 657.924644947052\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 8/200 | loss: 458.31908226013184\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 9/200 | loss: 328.5776525735855\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 10/200 | loss: 253.5048424601555\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 11/200 | loss: 211.04987731575966\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 12/200 | loss: 184.05563589930534\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 13/200 | loss: 163.78820773214102\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 14/200 | loss: 150.996307477355\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 15/200 | loss: 139.3443819284439\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 16/200 | loss: 130.86021430790424\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 17/200 | loss: 122.96829815208912\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 18/200 | loss: 115.80124522745609\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 19/200 | loss: 111.16016609221697\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 20/200 | loss: 107.91132833063602\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 21/200 | loss: 103.4878181219101\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 22/200 | loss: 99.42651282995939\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 23/200 | loss: 96.46091082692146\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 24/200 | loss: 92.98825667053461\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 25/200 | loss: 91.43861205875874\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 26/200 | loss: 89.16373300552368\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 27/200 | loss: 87.64070652425289\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 28/200 | loss: 84.80302656441927\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 29/200 | loss: 83.28509482741356\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 30/200 | loss: 81.02435701340437\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 31/200 | loss: 78.69785924255848\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 32/200 | loss: 77.65034997463226\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 33/200 | loss: 76.33820487558842\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 34/200 | loss: 75.86003819480538\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 35/200 | loss: 73.42882568389177\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 36/200 | loss: 71.88666969537735\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 37/200 | loss: 70.75630359351635\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 38/200 | loss: 69.80517399311066\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 39/200 | loss: 68.66285616531968\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 40/200 | loss: 67.8950406871736\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 41/200 | loss: 68.25417562946677\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 42/200 | loss: 67.78225027024746\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 43/200 | loss: 67.93793026357889\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 44/200 | loss: 66.40753728151321\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 45/200 | loss: 65.0454496704042\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 46/200 | loss: 63.93562067300081\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 47/200 | loss: 63.73981272429228\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 48/200 | loss: 63.43762278556824\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 49/200 | loss: 62.79183518141508\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 50/200 | loss: 62.22854483500123\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 51/200 | loss: 61.479368925094604\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 52/200 | loss: 61.27116774767637\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 53/200 | loss: 61.09705801308155\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 54/200 | loss: 60.53864540532231\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 55/200 | loss: 60.06485294178128\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 56/200 | loss: 59.5418304502964\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 57/200 | loss: 59.44907874614\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 58/200 | loss: 58.99070093780756\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 59/200 | loss: 58.208706613630056\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 60/200 | loss: 57.88137635588646\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 61/200 | loss: 58.00145500153303\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 62/200 | loss: 58.4331611096859\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 63/200 | loss: 57.812100406736135\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 64/200 | loss: 57.41121983900666\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 65/200 | loss: 56.836722027510405\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 66/200 | loss: 56.27666115760803\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 67/200 | loss: 56.8471395932138\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 68/200 | loss: 56.452370969578624\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 69/200 | loss: 56.191851168870926\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 70/200 | loss: 55.71430517360568\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 71/200 | loss: 55.0157789811492\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 72/200 | loss: 54.78734011761844\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 73/200 | loss: 54.02180816978216\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 74/200 | loss: 53.77819091081619\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 75/200 | loss: 53.49788128584623\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 76/200 | loss: 52.96603720076382\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 77/200 | loss: 52.59363328665495\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 78/200 | loss: 52.43304833956063\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 79/200 | loss: 52.84897521138191\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 80/200 | loss: 52.772211126983166\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 81/200 | loss: 52.33805414289236\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 82/200 | loss: 51.89404205232859\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 83/200 | loss: 51.74774980917573\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 84/200 | loss: 51.48110268265009\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 85/200 | loss: 51.34534738212824\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 86/200 | loss: 52.76155908033252\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 87/200 | loss: 52.171639043837786\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 88/200 | loss: 51.69684533774853\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 89/200 | loss: 51.26553962007165\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 90/200 | loss: 50.97409597784281\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 91/200 | loss: 50.832615016028285\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 92/200 | loss: 51.014018619433045\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 93/200 | loss: 50.93420509621501\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 94/200 | loss: 50.67099241819233\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 95/200 | loss: 50.67857941053808\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 96/200 | loss: 51.69674164801836\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 97/200 | loss: 51.02556128613651\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 98/200 | loss: 50.73588149063289\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 99/200 | loss: 51.022303719073534\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 100/200 | loss: 50.62003555893898\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 101/200 | loss: 50.17205220647156\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 102/200 | loss: 50.10909426026046\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 103/200 | loss: 49.50442860275507\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 104/200 | loss: 49.04684402421117\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 105/200 | loss: 48.74843830242753\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 106/200 | loss: 48.64485751464963\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 107/200 | loss: 48.547543954104185\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 108/200 | loss: 48.07887096889317\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 109/200 | loss: 48.42953426577151\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 110/200 | loss: 47.91238611750305\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 111/200 | loss: 47.729281798005104\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 112/200 | loss: 47.55656608566642\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 113/200 | loss: 48.241931080818176\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 114/200 | loss: 47.80836537480354\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 115/200 | loss: 47.71439500525594\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 116/200 | loss: 47.85857960674912\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 117/200 | loss: 47.81786785274744\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 118/200 | loss: 48.24200359545648\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 119/200 | loss: 47.85443826392293\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 120/200 | loss: 47.60155247151852\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 121/200 | loss: 47.26344585698098\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 122/200 | loss: 46.85039313323796\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 123/200 | loss: 46.628003591671586\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 124/200 | loss: 46.467406421899796\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 125/200 | loss: 46.486507561057806\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 126/200 | loss: 46.31683400273323\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 127/200 | loss: 46.237722700461745\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 128/200 | loss: 46.30311691015959\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 129/200 | loss: 46.167712066322565\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 130/200 | loss: 46.1687431409955\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 131/200 | loss: 46.13728652521968\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 132/200 | loss: 46.073673160746694\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 133/200 | loss: 45.70378436334431\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 134/200 | loss: 45.727748623117805\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 135/200 | loss: 45.60985533334315\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 136/200 | loss: 45.86456840764731\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 137/200 | loss: 45.85987281985581\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 138/200 | loss: 45.60205937549472\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 139/200 | loss: 45.32938954420388\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 140/200 | loss: 45.35462487488985\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 141/200 | loss: 45.171573830768466\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 142/200 | loss: 45.10584317520261\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 143/200 | loss: 44.941728497855365\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 144/200 | loss: 45.100033320486546\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 145/200 | loss: 45.89475396648049\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 146/200 | loss: 45.76616485975683\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 147/200 | loss: 45.59663185290992\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 148/200 | loss: 45.277290077880025\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 149/200 | loss: 45.096073031425476\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 150/200 | loss: 44.990468501113355\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 151/200 | loss: 44.894117165356874\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 152/200 | loss: 44.78844052553177\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 153/200 | loss: 44.58509712293744\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 154/200 | loss: 44.38486407324672\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 155/200 | loss: 44.19617347419262\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 156/200 | loss: 44.21854747645557\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 157/200 | loss: 44.10886763781309\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 158/200 | loss: 43.892337219789624\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 159/200 | loss: 43.841382588259876\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 160/200 | loss: 43.85859736613929\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 161/200 | loss: 44.0745576582849\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 162/200 | loss: 43.87930086906999\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 163/200 | loss: 43.89068173058331\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 164/200 | loss: 43.79071015305817\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 165/200 | loss: 43.6520115416497\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 166/200 | loss: 43.63697297871113\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 167/200 | loss: 43.32352195493877\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 168/200 | loss: 43.367006313055754\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 169/200 | loss: 43.20568034052849\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 170/200 | loss: 43.06165754236281\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 171/200 | loss: 43.02491548843682\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 172/200 | loss: 42.98068192601204\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 173/200 | loss: 42.895297065377235\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 174/200 | loss: 42.91508345492184\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 175/200 | loss: 42.99383767135441\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 176/200 | loss: 42.6211768258363\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 177/200 | loss: 42.68306392803788\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 178/200 | loss: 42.4695887779817\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 179/200 | loss: 42.40249792672694\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 180/200 | loss: 42.61289303004742\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 181/200 | loss: 42.42736889887601\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 182/200 | loss: 42.45540098659694\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 183/200 | loss: 42.18996760528535\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 184/200 | loss: 42.10613611899316\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 185/200 | loss: 42.045102338306606\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 186/200 | loss: 42.06534830480814\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 187/200 | loss: 41.96147551573813\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 188/200 | loss: 41.889104650355875\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 189/200 | loss: 41.91373281739652\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 190/200 | loss: 41.905943132936954\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 191/200 | loss: 41.820748848840594\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 192/200 | loss: 41.72684996854514\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 193/200 | loss: 41.735801733098924\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 194/200 | loss: 41.72535215690732\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 195/200 | loss: 41.70706699974835\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 196/200 | loss: 41.77386116050184\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 197/200 | loss: 42.235143914818764\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 198/200 | loss: 42.44642296247184\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 199/200 | loss: 42.07627071067691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3PadJPURcQs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}